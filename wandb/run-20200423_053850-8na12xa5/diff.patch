diff --git a/sweep.yaml b/sweep.yaml
index 539bb81..ab6d0f0 100644
--- a/sweep.yaml
+++ b/sweep.yaml
@@ -1,27 +1,23 @@
-sweep.yaml in same folder
-
-wandb.sweep(sfuisdgu.yaml)
-wandb.agent
-
-Example YAML
+# sweep.yaml
 program: train.py
-method: grid
+method: bayes
 metric:
-  goal: minimize
-  name: loss
+ name: acc #val_acc?
+ goal: maximize
 parameters:
-  dropout:
-    values: [0.1, 0.2, 0.4, 0.5, 0.7]
-  channels_one:
-    values: [10, 12, 14, 16, 18, 20]
-  channels_two:
-    values: [24, 28, 32, 36, 40, 44]
-  learning_rate:
-    values: [0.001, 0.005, 0.0005]
-  epochs:
-    value: 27
+ #learning-rate:
+   #min: 0.00001
+   #max: 0.1
+ #optimizer:
+   #values: ["adam", "sgd"]
+ #hidden_layer_size:
+   #values: [96, 128, 148]
+ epochs:
+   value: 50
+ read_docs: 
+   values: [250, 500, 1000, 2000, 4000]
 early_terminate:
-  type: hyperband
-  s: 2
-  eta: 3
-  max_iter: 27
\ No newline at end of file
+   type: hyperband
+   s: 2
+   eta: 3
+   max_iter: 25
\ No newline at end of file
diff --git a/train.py b/train.py
index 3795c0f..bc9e65e 100644
--- a/train.py
+++ b/train.py
@@ -41,7 +41,6 @@ config.doc_acc_sample_size = 25 # how many documents to check extraction on afte
 config.penalize_missed = 5 # how much more a missed 1 counts than a missed 0 in output
 config.val_split = 0.2
 
-
 source_data = 'source/training.csv'
 pickle_destination = 'source/cached_features.p'
 source_rows = 2000
@@ -125,7 +124,6 @@ def load_training_data(config):
 
 	return slugs, token_text, features,labels
 
-	
 # ---- Resample features,labels as windows ----
 
 # returns a window of tokens, labels at a random position in a random document
